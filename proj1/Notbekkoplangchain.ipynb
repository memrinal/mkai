{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f210fe44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– Mistral:  Electric cars offer several significant benefits compared to traditional internal combustion engine vehicles:\n",
      "\n",
      "1. Environmental Impact: Electric cars produce zero tailpipe emissions, which helps reduce air pollution and greenhouse gas emissions.\n",
      "\n",
      "2. Energy Efficiency: Electric motors convert energy more efficiently than internal combustion engines, resulting in fewer losses as heat and greater overall efficiency.\n",
      "\n",
      "3. Cost Savings: While the upfront cost of electric cars can be higher, they are cheaper to run over time due to lower fuel costs (electricity is typically cheaper than gasoline or diesel) and reduced maintenance needs.\n",
      "\n",
      "4. Reduced Dependence on Fossil Fuels: Electric cars can be charged using renewable energy sources such as solar or wind power, reducing our dependence on fossil fuels.\n",
      "\n",
      "5. Quiet Operation: Electric cars are much quieter than traditional cars, which can lead to less noise pollution in urban areas.\n",
      "\n",
      "6. Improved Performance: Electric motors provide instant torque, resulting in quick acceleration and smooth driving experiences.\n",
      "\n",
      "7. Technological Innovation: The rise of electric vehicles has led to significant advancements in battery technology, charging infrastructure, and smart grid management systems.\n",
      "\n",
      "8. Contribution to Grid Stability: Electric cars can serve as mobile energy storage units when equipped with bi-directional chargers, helping to balance the electrical grid during peak demand periods.\n"
     ]
    }
   ],
   "source": [
    "# Import LangChain core\n",
    "import langchain as lc\n",
    "\n",
    "# Import Ollama LLM wrapper from LangChain community\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "# Optional: If you were using OpenAI before, this is how it looked\n",
    "# from langchain_openai import OpenAI\n",
    "\n",
    "# Import message schema\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "\n",
    "# Set up the local Mistral model via Ollama\n",
    "llm = Ollama(model=\"mistral\")\n",
    "\n",
    "# Define a simple conversation\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"What are the benefits of electric cars?\")\n",
    "]\n",
    "\n",
    "# Run the conversation\n",
    "response = llm.invoke(messages)\n",
    "print(\"ðŸ¤– Mistral:\", response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
